{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee248e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Extração INMET ---\n",
      "[LOG] Encontrados 27 arquivos anuais.\n",
      "  [INMET] Baixando ZIP de 2000...\n",
      "    [AVISO] Estação não encontrada no ZIP de 2000.\n",
      "  [INMET] Baixando ZIP de 2001...\n",
      "    [AVISO] Estação não encontrada no ZIP de 2001.\n",
      "  [INMET] Baixando ZIP de 2002...\n",
      "    [AVISO] Estação não encontrada no ZIP de 2002.\n",
      "  [INMET] Baixando ZIP de 2003...\n",
      "    [AVISO] Estação não encontrada no ZIP de 2003.\n",
      "  [INMET] Baixando ZIP de 2004...\n",
      "    [AVISO] Estação não encontrada no ZIP de 2004.\n",
      "  [INMET] Baixando ZIP de 2005...\n",
      "    [AVISO] Estação não encontrada no ZIP de 2005.\n",
      "  [INMET] Baixando ZIP de 2006...\n",
      "    [ACHOU] Extraindo: 2006/INMET_SE_MG_A521_PAMPULHA_10-10-2006_A_31-12-2006.CSV\n",
      "    [SQLITE] 1992 linhas inseridas com sucesso.\n",
      "  [INMET] Baixando ZIP de 2007...\n",
      "    [ACHOU] Extraindo: 2007/INMET_SE_MG_A521_PAMPULHA_01-01-2007_A_31-12-2007.CSV\n",
      "    [SQLITE] 8760 linhas inseridas com sucesso.\n",
      "  [INMET] Baixando ZIP de 2008...\n",
      "    [ACHOU] Extraindo: 2008/INMET_SE_MG_A521_PAMPULHA_01-01-2008_A_31-12-2008.CSV\n",
      "    [SQLITE] 8784 linhas inseridas com sucesso.\n",
      "  [INMET] Baixando ZIP de 2009...\n",
      "    [ACHOU] Extraindo: 2009/INMET_SE_MG_A521_PAMPULHA_01-01-2009_A_31-12-2009.CSV\n",
      "    [SQLITE] 8760 linhas inseridas com sucesso.\n",
      "  [INMET] Baixando ZIP de 2010...\n",
      "    [ACHOU] Extraindo: 2010/INMET_SE_MG_A521_PAMPULHA_01-01-2010_A_31-12-2010.CSV\n",
      "    [SQLITE] 8760 linhas inseridas com sucesso.\n",
      "  [INMET] Baixando ZIP de 2011...\n",
      "    [ACHOU] Extraindo: 2011/INMET_SE_MG_A521_PAMPULHA_01-01-2011_A_31-12-2011.CSV\n",
      "    [SQLITE] 8760 linhas inseridas com sucesso.\n",
      "  [INMET] Baixando ZIP de 2012...\n",
      "    [ACHOU] Extraindo: 2012/INMET_SE_MG_A521_PAMPULHA_01-01-2012_A_31-12-2012.CSV\n",
      "    [SQLITE] 8784 linhas inseridas com sucesso.\n",
      "  [INMET] Baixando ZIP de 2013...\n",
      "    [ACHOU] Extraindo: 2013/INMET_SE_MG_A521_PAMPULHA_01-01-2013_A_31-12-2013.CSV\n",
      "    [SQLITE] 8760 linhas inseridas com sucesso.\n",
      "  [INMET] Baixando ZIP de 2014...\n",
      "    [ACHOU] Extraindo: 2014/INMET_SE_MG_A521_PAMPULHA_01-01-2014_A_31-12-2014.CSV\n",
      "    [SQLITE] 8760 linhas inseridas com sucesso.\n",
      "  [INMET] Baixando ZIP de 2015...\n",
      "    [ACHOU] Extraindo: 2015/INMET_SE_MG_A521_PAMPULHA_01-01-2015_A_31-12-2015.CSV\n",
      "    [SQLITE] 8760 linhas inseridas com sucesso.\n",
      "  [INMET] Baixando ZIP de 2016...\n",
      "    [ACHOU] Extraindo: 2016/INMET_SE_MG_A521_PAMPULHA_01-01-2016_A_31-12-2016.CSV\n",
      "    [SQLITE] 8784 linhas inseridas com sucesso.\n",
      "  [INMET] Baixando ZIP de 2017...\n",
      "    [ACHOU] Extraindo: 2017/INMET_SE_MG_A521_PAMPULHA_01-01-2017_A_31-12-2017.CSV\n",
      "    [SQLITE] 8760 linhas inseridas com sucesso.\n",
      "  [INMET] Baixando ZIP de 2018...\n",
      "    [ACHOU] Extraindo: 2018/INMET_SE_MG_A521_PAMPULHA_01-01-2018_A_31-12-2018.CSV\n",
      "    [SQLITE] 8760 linhas inseridas com sucesso.\n",
      "  [INMET] Baixando ZIP de 2019...\n",
      "    [ERRO] Falha no ano 2019: ('Connection broken: IncompleteRead(10518528 bytes read, 107041673 more expected)', IncompleteRead(10518528 bytes read, 107041673 more expected))\n",
      "  [INMET] Baixando ZIP de 2020...\n",
      "    [ERRO] Falha no ano 2020: HTTPSConnectionPool(host='portal.inmet.gov.br', port=443): Max retries exceeded with url: /uploads/dadoshistoricos/2020.zip (Caused by NameResolutionError(\"HTTPSConnection(host='portal.inmet.gov.br', port=443): Failed to resolve 'portal.inmet.gov.br' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  [INMET] Baixando ZIP de 2021...\n",
      "    [ERRO] Falha no ano 2021: HTTPSConnectionPool(host='portal.inmet.gov.br', port=443): Max retries exceeded with url: /uploads/dadoshistoricos/2021.zip (Caused by NameResolutionError(\"HTTPSConnection(host='portal.inmet.gov.br', port=443): Failed to resolve 'portal.inmet.gov.br' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  [INMET] Baixando ZIP de 2022...\n",
      "    [ERRO] Falha no ano 2022: HTTPSConnectionPool(host='portal.inmet.gov.br', port=443): Max retries exceeded with url: /uploads/dadoshistoricos/2022.zip (Caused by NameResolutionError(\"HTTPSConnection(host='portal.inmet.gov.br', port=443): Failed to resolve 'portal.inmet.gov.br' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  [INMET] Baixando ZIP de 2023...\n",
      "    [ERRO] Falha no ano 2023: HTTPSConnectionPool(host='portal.inmet.gov.br', port=443): Max retries exceeded with url: /uploads/dadoshistoricos/2023.zip (Caused by NameResolutionError(\"HTTPSConnection(host='portal.inmet.gov.br', port=443): Failed to resolve 'portal.inmet.gov.br' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  [INMET] Baixando ZIP de 2024...\n",
      "    [ERRO] Falha no ano 2024: HTTPSConnectionPool(host='portal.inmet.gov.br', port=443): Max retries exceeded with url: /uploads/dadoshistoricos/2024.zip (Caused by NameResolutionError(\"HTTPSConnection(host='portal.inmet.gov.br', port=443): Failed to resolve 'portal.inmet.gov.br' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  [INMET] Baixando ZIP de 2025...\n",
      "    [ERRO] Falha no ano 2025: HTTPSConnectionPool(host='portal.inmet.gov.br', port=443): Max retries exceeded with url: /uploads/dadoshistoricos/2025.zip (Caused by NameResolutionError(\"HTTPSConnection(host='portal.inmet.gov.br', port=443): Failed to resolve 'portal.inmet.gov.br' ([Errno 11001] getaddrinfo failed)\"))\n",
      "  [INMET] Baixando ZIP de 2026...\n",
      "    [ERRO] Falha no ano 2026: HTTPSConnectionPool(host='portal.inmet.gov.br', port=443): Max retries exceeded with url: /uploads/dadoshistoricos/2026.zip (Caused by NameResolutionError(\"HTTPSConnection(host='portal.inmet.gov.br', port=443): Failed to resolve 'portal.inmet.gov.br' ([Errno 11001] getaddrinfo failed)\"))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import io\n",
    "import zipfile\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "\n",
    "# --- CONFIGURAÇÕES ---\n",
    "URL_INMET = \"https://portal.inmet.gov.br/dadoshistoricos\"\n",
    "DB_PATH = os.path.join('data', 'projeto_anac.db')\n",
    "PREFIXO_ARQUIVO_ALVO = \"PAMPULHA\"\n",
    "\n",
    "def padronizar_coluna(nome_original):\n",
    "    nome_original = unidecode(nome_original).upper()\n",
    "    \n",
    "    # Mapeamento com as suas traduções em camelCase\n",
    "    mapeamento = {\n",
    "        # Datas e Horas\n",
    "        'HORA (UTC)': 'hora',\n",
    "        'HORA UTC': 'hora',\n",
    "        'DATA (YYYY-MM-DD)': 'data',\n",
    "        'DATA': 'data',\n",
    "        \n",
    "        # Pressão (Específicas primeiro)\n",
    "        'PRESSAO ATMOSFERICA MAX': 'pressaoAtmosfericaMaxUltimaHora',\n",
    "        'PRESSAO ATMOSFERICA MIN': 'pressaoAtmosfericaMinUltimaHora',\n",
    "        'PRESSAO ATMOSFERICA AO NIVEL': 'pressaoAtmosferica',\n",
    "        \n",
    "        # Temperatura (Específicas primeiro)\n",
    "        'TEMPERATURA ORVALHO MAX': 'temperaturaPontoOrvalhoMaxUltimaHora',\n",
    "        'TEMPERATURA ORVALHO MIN': 'temperaturaPontoOrvalhoMinUltimaHora',\n",
    "        'TEMPERATURA MAXIMA': 'temperaturaMaxUltimaHora',\n",
    "        'TEMPERATURA MINIMA': 'temperaturaMinUltimaHora',\n",
    "        'TEMPERATURA DO AR - BULBO SECO': 'temperaturaBulboSeco',\n",
    "        'TEMPERATURA DO PONTO DE ORVALHO': 'temperaturaPontoOrvalho',\n",
    "        \n",
    "        # Umidade (Específicas primeiro)\n",
    "        'UMIDADE REL. MAX': 'umidadeRelativaMaxUltimaHora',\n",
    "        'UMIDADE REL. MIN': 'umidadeRelativaMinUltimaHora',\n",
    "        'UMIDADE RELATIVA': 'umidadeRelativa',\n",
    "        \n",
    "        # Vento e Outros\n",
    "        'VENTO, RAJADA': 'ventoRajadaMax',\n",
    "        'VENTO, VELOCIDADE': 'ventoVelocidade',\n",
    "        'VENTO, DIRECAO': 'ventoDirecaoGraus',\n",
    "        'PRECIPITACAO': 'precipitacaoTotal',\n",
    "        'RADIACAO': 'radiacaoGlobal'\n",
    "    }\n",
    "\n",
    "    for chave, nome_traduzido in mapeamento.items():\n",
    "        if chave in nome_original:\n",
    "            return nome_traduzido\n",
    "            \n",
    "    # Caso apareça algo novo, mantém um padrão camelCase básico\n",
    "    return unidecode(nome_original).title().replace(' ', '').strip()\n",
    "\n",
    "\n",
    "def processar_zip_inmet(url_zip, ano):\n",
    "    try:\n",
    "        print(f\"  [INMET] Baixando ZIP de {ano}...\")\n",
    "        r = requests.get(url_zip, timeout=60) # Aumentado timeout para arquivos grandes\n",
    "        r.raise_for_status()\n",
    "\n",
    "        with zipfile.ZipFile(io.BytesIO(r.content)) as z:\n",
    "            lista_arquivos = z.namelist()\n",
    "            arquivo_alvo = next((f for f in lista_arquivos if PREFIXO_ARQUIVO_ALVO in f), None)\n",
    "            \n",
    "            if arquivo_alvo:\n",
    "                print(f\"    [ACHOU] Extraindo: {arquivo_alvo}\")\n",
    "                with z.open(arquivo_alvo) as f:\n",
    "                    # O INMET usa latin-1 e ;\n",
    "                    df = pd.read_csv(f, sep=';', encoding='latin-1', skiprows=8)\n",
    "                    \n",
    "                    # --- PADRONIZAÇÃO DE COLUNAS ---\n",
    "                    # 1. Remove colunas vazias (comum no final dos CSVs do INMET)\n",
    "                    df = df.dropna(axis=1, how='all')\n",
    "                    \n",
    "                    # APLICA A NOVA PADRONIZAÇÃO (Chama a função para cada coluna)\n",
    "                    df.columns = [padronizar_coluna(c) for c in df.columns]\n",
    "                    \n",
    "                    df['anoRef'] = ano\n",
    "\n",
    "                    df = df.replace(',', '.')\n",
    "                    \n",
    "                    with sqlite3.connect(DB_PATH) as conn:\n",
    "                        # Agora o append funcionará pois as colunas são idênticas\n",
    "                        df.to_sql('clima_inmet', conn, if_exists='append', index=False)\n",
    "                    \n",
    "                    print(f\"    [SQLITE] {len(df)} linhas inseridas com sucesso.\")\n",
    "            else:\n",
    "                print(f\"    [AVISO] Estação não encontrada no ZIP de {ano}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    [ERRO] Falha no ano {ano}: {e}\")\n",
    "\n",
    "\n",
    "def extrair_dados_inmet():\n",
    "    print(f\"\\n--- Iniciando Extração INMET ---\")\n",
    "    try:\n",
    "        # Nota: O portal do INMET às vezes bloqueia requests sem User-Agent\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        response = requests.get(URL_INMET, headers=headers, timeout=20)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Encontra todos os links que terminam em .zip\n",
    "        links = soup.find_all('a', href=True)\n",
    "        zips_encontrados = [l['href'] for l in links if l['href'].endswith('.zip')]\n",
    "        \n",
    "        print(f\"[LOG] Encontrados {len(zips_encontrados)} arquivos anuais.\")\n",
    "\n",
    "        for url_zip in zips_encontrados:\n",
    "            # Extrai o ano do nome do arquivo (ex: 2023.zip -> 2023)\n",
    "            ano = url_zip.split('/')[-1].replace('.zip', '')    \n",
    "            processar_zip_inmet(url_zip, ano)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERRO CRÍTICO INMET] {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Garante pasta de dados\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    \n",
    "    # Inicia a automação\n",
    "    extrair_dados_inmet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c9343d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\Pichau\\Downloads\\VRA_20001.csv\", skiprows=1, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b55907e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ICAO Empresa Aérea</th>\n",
       "      <th>Número Voo</th>\n",
       "      <th>Código Autorização (DI)</th>\n",
       "      <th>Código Tipo Linha</th>\n",
       "      <th>ICAO Aeródromo Origem</th>\n",
       "      <th>ICAO Aeródromo Destino</th>\n",
       "      <th>Partida Prevista</th>\n",
       "      <th>Partida Real</th>\n",
       "      <th>Chegada Prevista</th>\n",
       "      <th>Chegada Real</th>\n",
       "      <th>Situação Voo</th>\n",
       "      <th>Código Justificativa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TAM</td>\n",
       "      <td>4660</td>\n",
       "      <td>0</td>\n",
       "      <td>R</td>\n",
       "      <td>SBCX</td>\n",
       "      <td>SBCT</td>\n",
       "      <td>01/01/2000 05:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/01/2000 06:37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CANCELADO</td>\n",
       "      <td>XS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VRG</td>\n",
       "      <td>8710</td>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "      <td>MMMX</td>\n",
       "      <td>SBEG</td>\n",
       "      <td>01/01/2000 19:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02/01/2000 01:25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REALIZADO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLC</td>\n",
       "      <td>8250</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>SBBR</td>\n",
       "      <td>SBGO</td>\n",
       "      <td>01/01/2000 20:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/01/2000 20:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REALIZADO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLC</td>\n",
       "      <td>241</td>\n",
       "      <td>9</td>\n",
       "      <td>R</td>\n",
       "      <td>SBSP</td>\n",
       "      <td>SBKP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/01/2000 22:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/01/2000 22:45</td>\n",
       "      <td>REALIZADO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RSL</td>\n",
       "      <td>7161</td>\n",
       "      <td>9</td>\n",
       "      <td>R</td>\n",
       "      <td>SBRJ</td>\n",
       "      <td>SBCF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/01/2000 10:46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01/01/2000 11:35</td>\n",
       "      <td>REALIZADO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ICAO Empresa Aérea  Número Voo  Código Autorização (DI) Código Tipo Linha  \\\n",
       "0                TAM        4660                        0                 R   \n",
       "1                VRG        8710                        0                 I   \n",
       "2                BLC        8250                        0                 N   \n",
       "3                BLC         241                        9                 R   \n",
       "4                RSL        7161                        9                 R   \n",
       "\n",
       "  ICAO Aeródromo Origem ICAO Aeródromo Destino  Partida Prevista  \\\n",
       "0                  SBCX                   SBCT  01/01/2000 05:45   \n",
       "1                  MMMX                   SBEG  01/01/2000 19:00   \n",
       "2                  SBBR                   SBGO  01/01/2000 20:04   \n",
       "3                  SBSP                   SBKP               NaN   \n",
       "4                  SBRJ                   SBCF               NaN   \n",
       "\n",
       "       Partida Real  Chegada Prevista      Chegada Real Situação Voo  \\\n",
       "0               NaN  01/01/2000 06:37               NaN    CANCELADO   \n",
       "1               NaN  02/01/2000 01:25               NaN    REALIZADO   \n",
       "2               NaN  01/01/2000 20:30               NaN    REALIZADO   \n",
       "3  01/01/2000 22:06               NaN  01/01/2000 22:45    REALIZADO   \n",
       "4  01/01/2000 10:46               NaN  01/01/2000 11:35    REALIZADO   \n",
       "\n",
       "  Código Justificativa  \n",
       "0                   XS  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dee9549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICAO Empresa Aérea\n",
      "Número Voo\n",
      "Código Autorização (DI)\n",
      "Código Tipo Linha\n",
      "ICAO Aeródromo Origem\n",
      "ICAO Aeródromo Destino\n",
      "Partida Prevista\n",
      "Partida Real\n",
      "Chegada Prevista\n",
      "Chegada Real\n",
      "Situação Voo\n",
      "Código Justificativa\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3edde33",
   "metadata": {},
   "outputs": [],
   "source": [
    "'ICAO Empresa Aérea',\n",
    "'Número Voo',\n",
    "'Código Autorização (DI)',\n",
    "'Código Tipo Linha',\n",
    "'ICAO Aeródromo Origem',\n",
    "'ICAO Aeródromo Destino',\n",
    "'Partida Prevista',\n",
    "'Partida Real',\n",
    "'Chegada Prevista',\n",
    "'Chegada Real',\n",
    "'Situação Voo',\n",
    "'Código Justificativa'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
